{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A notebook containing the majority of analysis code used to not only investigate model outputs, but to also generate the images found in the report. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import mglearn.tools\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import sklearn.metrics as skm\n",
    "\n",
    "from SERA import SERA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(file):\n",
    "    \"\"\"calculates the predicted range, true range, pearson correlation \n",
    "    coefficient, and the spearman rank correlation coefficient from a \n",
    "    PointVS output file\"\"\"\n",
    "    \n",
    "    true, pred = [], []\n",
    "    with open(file) as f:\n",
    "        for line in f.readlines():\n",
    "            true.append(float(line[0:6].strip()))\n",
    "            pred.append(float(line[8:14].strip()))\n",
    "\n",
    "    print ('pred_range:', np.max(pred) - np.min(pred))\n",
    "    print ('true_range:', np.max(true) - np.min(true))\n",
    "    print ('PCC:', np.corrcoef(true, pred)[0][1])\n",
    "    print ('SPCC', stats.spearmanr(true, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distribution(file):\n",
    "    '''Plots true and predicted distributions from pointvs outputs file.\n",
    "    The bins of the histogram were defined dependending on the image being \n",
    "    produced for the report.'''\n",
    "    \n",
    "    true, pred = [], []\n",
    "    with open(file) as f:\n",
    "        for line in f.readlines():\n",
    "            true.append(float(line[0:6].strip()))\n",
    "            pred.append(float(line[8:14].strip()))\n",
    "\n",
    "    \n",
    "    #bins=np.histogram(np.hstack((true,pred)), bins=46)[1] #get the bin edges\n",
    "    bins=[i for i in np.arange(-3, 15.0, 0.3)]\n",
    "    fig, ax1 = plt.subplots()\n",
    "    ax1.hist(true, bins, color='red', alpha=0.8)\n",
    "    ax1.set_ylim(0, 260)\n",
    "    ax1.hist(pred, bins, color='blue', alpha=0.5)\n",
    "    ax1.set_xlim(-3, 15.4)\n",
    "    ax1.set_xlabel('pKd')\n",
    "    ax1.set_ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist_et_interpol(file, control):\n",
    "    '''Plots true and predicted distributions from pointvs outputs file,\n",
    "    as well as the interpolation relevance curve generated from the supplied\n",
    "    control points. The bins of the histogram were defined dependending on the \n",
    "    image being produced for the report.'''\n",
    "\n",
    "    true, pred = [], []\n",
    "    with open(file) as f:\n",
    "        for line in f.readlines():\n",
    "            true.append(float(line[0:6].strip()))\n",
    "            pred.append(float(line[8:14].strip()))\n",
    "\n",
    "    bounds = SERA._relevance_interval(true)\n",
    "    y_true = SERA.filter_outliers(true, true, bounds)[0]\n",
    "\n",
    "    x, y, control_set, relevance = SERA.interpolator(y_true, bounds, control)[1:]\n",
    "\n",
    "    fig, ax1 = plt.subplots()\n",
    "    ax2 = ax1.twinx()\n",
    "    #bins=np.histogram(np.hstack((true,pred)), bins=40)[1]\n",
    "     #get the bin edges\n",
    "    bins=[i for i in np.arange(-3, 15.0, 0.3)]\n",
    "    ax1.hist(true, bins, color='red', alpha=0.8)\n",
    "    ax1.hist(pred, bins, color='blue', alpha=0.5)\n",
    "    ax2.plot(x, y)\n",
    "    ax2.plot(control_set, relevance, \"o\")\n",
    "    ax1.set_xlabel('pKd')\n",
    "    ax1.set_ylabel('Frequency')\n",
    "    ax2.set_ylabel('Relevance')\n",
    "    ax2.set_ylim(-0.050, 1.05)\n",
    "    ax1.set_ylim(0, 260)\n",
    "    ax1.set_xlim(-3, 15.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCC_comparison(file_dict):\n",
    "    '''\n",
    "    Plots the pearson correlation coefficient for each epoch\n",
    "    output file, which must be passed in as a list in a dictionary with the \n",
    "    model names as keys.\n",
    "    \n",
    "    e.g) PCC_comparison({\"SERA_1_0_1\":[epoch_1_output.txt, epoch_2_output.txt]})\n",
    "    \n",
    "    '''\n",
    "    pcc_dict = {}\n",
    "    for k, model in file_dict.items():\n",
    "        PCC = []\n",
    "        for epoch in model:\n",
    "            true, pred = [], []\n",
    "            with open(epoch) as f:\n",
    "                for line in f.readlines():\n",
    "                    true.append(float(line[0:6].strip()))\n",
    "                    pred.append(float(line[8:14].strip()))\n",
    "                PCC.append(np.corrcoef(true, pred)[0][1])\n",
    "        pcc_dict[k] = PCC\n",
    "\n",
    "    fig, ax1 = plt.subplots()\n",
    "    for k, v in pcc_dict.items():\n",
    "        ax1.plot([i for i in range(2, len(v)+2)], v, label=k)\n",
    "    ax1.legend()\n",
    "    ax1.set_ylim(0.2, 0.5)\n",
    "    ax1.set_xlim(2, 10)\n",
    "    ax1.set_xlabel('epoch')\n",
    "    ax1.set_ylabel('Pearson Correlation Coefficient')\n",
    "    plt.grid(axis='y', alpha=0.5)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rho_comparison(file_dict):\n",
    "    '''\n",
    "    Plots the Spearman Rank Correlation Coefficient for each epoch\n",
    "    output file, which must be passed in as a list in a dictionary with the \n",
    "    model names as keys.\n",
    "    \n",
    "    e.g) rho_comparison({\"SERA_1_0_1\":[epoch_1_output.txt, epoch_2_output.txt]})\n",
    "    \n",
    "    '''\n",
    "    rho_dict = {}\n",
    "    for k, model in file_dict.items():\n",
    "        rho = []\n",
    "        for epoch in model:\n",
    "            true, pred = [], []\n",
    "            with open(epoch) as f:\n",
    "                for line in f.readlines():\n",
    "                    true.append(float(line[0:6].strip()))\n",
    "                    pred.append(float(line[8:14].strip()))\n",
    "                rho.append(stats.spearmanr(true, pred)[0])\n",
    "        rho_dict[k] = rho\n",
    "\n",
    "\n",
    "    fig, ax1 = plt.subplots()\n",
    "    for k, v in rho_dict.items():\n",
    "        ax1.plot([i for i in range(2, len(v)+2)], v, label=k)\n",
    "    ax1.legend()\n",
    "    ax1.set_ylim(0.2, 0.5)\n",
    "    ax1.set_xlim(2, 10)\n",
    "    ax1.set_xlabel('epoch')\n",
    "    ax1.set_ylabel('Spearman Rank Correlation Coefficient')\n",
    "    plt.grid(axis='y', alpha=0.5)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def active_metrics(file, thresh):\n",
    "    '''\n",
    "    Calculates accuracy, precision, sensitivity, false positive rate, \n",
    "    and specificity when a binary constraint is imposed as per a user defined\n",
    "    threshold. Compounds above this threshold are of the 'positive' class, while \n",
    "    compounds below the thresholds are 'negative'.\n",
    "    ''' \n",
    "      \n",
    "    true, pred = [], []\n",
    "    with open(file) as f:\n",
    "        for line in f.readlines():\n",
    "            true.append(float(line[0:6].strip()))\n",
    "            pred.append(float(line[8:14].strip()))\n",
    "\n",
    "    TP, TN, FN, FP = [], [], [], []\n",
    "\n",
    "    for i in range(len(true)):\n",
    "        if true[i] >= thresh and pred[i] >= thresh:\n",
    "            TP.append(pred[i])\n",
    "        elif true[i] < thresh and pred[i] < thresh:\n",
    "            TN.append(pred[i])\n",
    "        elif true[i] >= thresh and pred[i] < thresh:\n",
    "            FN.append(pred[i])\n",
    "        elif true[i] < thresh and pred[i] >= thresh:\n",
    "            FP.append(pred[i])\n",
    "\n",
    "    accuracy = (len(TP) + len(TN))/(len(TP) + len(TN) + len(FN) + len(FP))\n",
    "    precision = len(TP) /(len(TP) + len(FP))\n",
    "    sensitivity = len(TP)/(len(TP) + len(FN))\n",
    "    FPR = len(FP)/(len(FP) + len(TN))\n",
    "    specificity = 1 - FPR\n",
    "\n",
    "    return ({'accuracy':accuracy, 'precision':precision, 'sensitivity':sensitivity, 'specificity':specificity, 'FPR':FPR})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class multiclass_metrics:\n",
    "    '''A class to divide the true and predicted values of the PointVS output\n",
    "    into multiclass classification style bins (as defined within the instantiation method).\n",
    "    A normlaised confusion matrix of these labels can be generated, as well as the spearman rank\n",
    "    correlation coefficient of the correctly predicted values in each bin.\n",
    "    \n",
    "    Bin metrics e.g) mutliclass_metrics('output_file.txt').bin_metrics()\n",
    "    Confusion matrix e.g) multiclass_metrics('output_file.txt').generate_confusion()\n",
    "    \n",
    "    '''\n",
    "\n",
    "    def __init__(self, file):\n",
    "\n",
    "        self.bins = {\n",
    "            \"-(4-3)\": (-4, -3),\n",
    "            \"-(3-2)\": (-3, -2),\n",
    "            \"-(2-1)\": (-2, -1),\n",
    "            \"-(1, 0)\": (-1, 0),\n",
    "            \"0-1\": (0, 1),\n",
    "            \"1-2\": (1, 2),\n",
    "            \"2-3\": (2, 3),\n",
    "            \"3-4\": (3, 4),\n",
    "            \"4-5\": (4, 5),\n",
    "            \"5-6\": (5, 6),\n",
    "            \"6-7\": (6, 7),\n",
    "            \"7-8\": (7, 8),\n",
    "            \"8-9\": (8, 9),\n",
    "            \"9-10\": (9, 10),\n",
    "            \"10-11\": (10, 11),\n",
    "            \"11-12\": (11, 12),\n",
    "            \"12-13\": (12, 13),\n",
    "            \"13-14\": (13, 14),\n",
    "            \"14-15\": (14, 15),\n",
    "            \"15-16\": (15, 16),\n",
    "        }\n",
    "\n",
    "        self.labels = [i for i in self.bins.keys()]\n",
    "\n",
    "        self.true, self.pred = self._extract_vals(file)\n",
    "\n",
    "        self.true, self.pred, self.map_bins_true, self.map_bins_pred = self.populate_bins()\n",
    "\n",
    "    def bin_metrics(self):\n",
    "        '''calculate the spearman rank correlation coefficient of each label'''\n",
    "\n",
    "        spcorr = {}\n",
    "        for k in self.bins.keys():\n",
    "            t, p = [], []\n",
    "            for i in range(len(self.map_bins_true)):\n",
    "                if list(self.map_bins_true[i].keys())[0] == k:\n",
    "                    if list(self.map_bins_pred[i].keys())[0] == k:\n",
    "                        t.append(list(self.map_bins_true[i].values())[0])\n",
    "                        p.append(list(self.map_bins_pred[i].values())[0])\n",
    "\n",
    "            spcorr[k] = stats.spearmanr(t, p)[0]\n",
    "        \n",
    "        return spcorr\n",
    "\n",
    "    def populate_bins(self):\n",
    "        '''divide the true and predicted values into mutliclass labels'''\n",
    "\n",
    "        bin_map_true, bin_map_pred = [], []\n",
    "        true_classes, pred_classes = [], []\n",
    "        for i in range(len(self.true)):\n",
    "            for label, bin in self.bins.items():\n",
    "                if bin[0] <= self.true[i] < bin[1]:\n",
    "                    true_classes.append(label)\n",
    "                    bin_map_true.append({label:self.true[i]})\n",
    "                if bin[0] <= self.pred[i] < bin[1]:\n",
    "                    pred_classes.append(label)\n",
    "                    bin_map_pred.append({label:self.pred[i]})\n",
    "\n",
    "        true_sorted, pred_sorted = [], []\n",
    "        for i in self.labels:\n",
    "            for j in range(0, len(true_classes)):\n",
    "                if true_classes[j] == i:\n",
    "                    true_sorted.append(true_classes[j])\n",
    "                    pred_sorted.append(pred_classes[j])\n",
    "\n",
    "        return true_sorted, pred_sorted, bin_map_true, bin_map_pred\n",
    "\n",
    "    def generate_confusion(self):\n",
    "        '''generate a normalised confusion matrix heatmap for the defined labels'''\n",
    "\n",
    "        matrix = skm.confusion_matrix(self.true, self.pred, labels=self.labels, normalize='true')\n",
    "\n",
    "        plt.figure(figsize=(15, 15))\n",
    "        matrix_image = mglearn.tools.heatmap(\n",
    "            matrix*100,\n",
    "            xlabel=\"predicted label\",\n",
    "            ylabel=\"true label\",\n",
    "            xticklabels=self.labels,\n",
    "            yticklabels=self.labels,\n",
    "            cmap=plt.cm.gray_r,\n",
    "            fmt=\"%d\",\n",
    "        )\n",
    "        plt.title(\"confusion matrix\")\n",
    "        plt.gca().invert_yaxis()\n",
    "\n",
    "    @staticmethod\n",
    "    def _extract_vals(file):\n",
    "        '''Extract true and predicted values from the PointVS output file'''\n",
    "        true, pred = [], []\n",
    "        with open(file) as f:\n",
    "            for line in f.readlines():\n",
    "                true.append(float(line[0:6].strip()))\n",
    "                pred.append(float(line[8:14].strip()))\n",
    "\n",
    "        return true, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('PointVS_eval')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "73054ae673eb7cc6494f8462c33a70255695a2e84abbdce75b9663d76df82988"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
